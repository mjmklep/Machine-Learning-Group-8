{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, learning_curve, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import RocCurveDisplay, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "import sklearn.metrics\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with zipfile.ZipFile(os.path.join(os.getcwd(),'Machine-Learning-Group-8','tm10007_ml','ecg','ecg_data.zip'), 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/tm10007_ml/ecg')\n",
    "\n",
    "data = pd.read_csv('/content/tm10007_ml/ecg/ecg_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot learning curve\n",
    "Inputs: \n",
    "- X_train\n",
    "- y_train\n",
    "- (Gefitte) classifier\n",
    "- scoring: str met je scoring methode, bijvoorbeeld 'error' of 'roc_auc'\n",
    "- clf_type: str met de naam van je classifier om te displayen in de titel van de plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(X_train, y_train, classifier, scoring, clf_type):\n",
    "    if scoring == 'error':\n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "            classifier,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=StratifiedKFold(n_splits=5),\n",
    "            scoring='accuracy',\n",
    "            train_sizes=np.linspace(0.1, 1.0, 50),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        train_scores_mean = 1-np.mean(train_scores, axis=1)\n",
    "        train_scores_std = np.std(train_scores, axis=1)\n",
    "        test_scores_mean = 1-np.mean(test_scores, axis=1)\n",
    "        test_scores_std = np.std(test_scores, axis=1)\n",
    "    else:\n",
    "        train_sizes, train_scores, test_scores = learning_curve(\n",
    "            classifier,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            cv=StratifiedKFold(n_splits=5),\n",
    "            scoring=scoring,\n",
    "            train_sizes=np.linspace(0.1, 1.0, 50),\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "        train_scores_std = np.std(train_scores, axis=1)\n",
    "        test_scores_mean = np.mean(test_scores, axis=1)\n",
    "        test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(f\"Learning Curve ({clf_type})\")\n",
    "    plt.xlabel(\"Number of training objects\")\n",
    "    plt.ylabel(scoring)\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', label=\"Training score\", color=\"blue\")\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                    train_scores_mean + train_scores_std, alpha=0.1, color=\"blue\")\n",
    "\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', label=\"Cross-validation score\", color=\"green\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                    test_scores_mean + test_scores_std, alpha=0.1, color=\"green\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model + plot ROC curves\n",
    "Pas tune_hyperparameters aan je classifier aan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_rf(X_train, y_train):\n",
    "    pipe = Pipeline([('feature_selection', SelectKBest(f_classif)), \n",
    "                 ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1, max_features='sqrt', class_weight='balanced'))\n",
    "                 ])\n",
    "\n",
    "    param_dist = {\n",
    "        'feature_selection__k': np.arange(100, 500, 10),\n",
    "        'classifier__n_estimators': np.arange(5, 20, 5),\n",
    "        'classifier__min_samples_split': np.arange(10, 50, 5),\n",
    "        'classifier__min_samples_leaf': np.arange(10, 50, 5),\n",
    "        'classifier__max_depth': [5, 10],\n",
    "        'classifier__criterion': ['gini', 'entropy'],\n",
    "        'classifier__bootstrap': [True, False]\n",
    "    }\n",
    "\n",
    "    n_iterations = 20\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "                                        pipe, \n",
    "                                        param_distributions=param_dist, \n",
    "                                        cv=StratifiedKFold(n_splits=5), \n",
    "                                        n_iter=n_iterations,\n",
    "                                        scoring='roc_auc', \n",
    "                                        n_jobs=-1\n",
    "                                        )\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameters:\", random_search.best_params_)\n",
    "    print(\"Best Score:\", random_search.best_score_)\n",
    "    return random_search.best_estimator_\n",
    "\n",
    "def plot_roc_cv(X, y, n_splits=5):\n",
    "    y = data.iloc[:,-1]\n",
    "    X = data.iloc[:,:-1]\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=n_splits)\n",
    "\n",
    "    tprs = []\n",
    "    aucs = []\n",
    "    best_classifier = None\n",
    "    best_auc = 0.0\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    for fold, (train, test) in enumerate(cv.split(X, y)):\n",
    "        X_train = X.iloc[train]\n",
    "        y_train = y.iloc[train]\n",
    "        X_test = X.iloc[test]\n",
    "        y_test = y.iloc[test]\n",
    "        classifier = optimize_rf(X_train, y_train)\n",
    "        viz = RocCurveDisplay.from_estimator(\n",
    "            classifier,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            name=f\"ROC fold {fold}\",\n",
    "            alpha=0.3,\n",
    "            lw=1,\n",
    "            ax=ax,\n",
    "            plot_chance_level=(fold == n_splits - 1),\n",
    "        )\n",
    "        interp_tpr = np.interp(mean_fpr, viz.fpr, viz.tpr)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(viz.roc_auc)\n",
    "\n",
    "        if viz.roc_auc > best_auc:\n",
    "            best_auc = viz.roc_auc\n",
    "            best_classifier = classifier\n",
    "            best_X_train = X_train\n",
    "            best_y_train = y_train\n",
    "\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        y_proba = classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        fold_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "        print(f\"Accuracy:  {accuracy:.3f}\")\n",
    "        print(f\"Precision: {precision:.3f}\")\n",
    "        print(f\"Recall:    {recall:.3f}\")\n",
    "        print(f\"F1 Score:  {f1:.3f}\")\n",
    "        print(f\"AUC Score: {fold_auc:.3f}\")\n",
    "\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = sklearn.metrics.auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(\n",
    "        mean_fpr,\n",
    "        mean_tpr,\n",
    "        color=\"b\",\n",
    "        label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "\n",
    "    std_tpr = np.std(tprs, axis=0)\n",
    "    tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(\n",
    "        mean_fpr,\n",
    "        tprs_lower,\n",
    "        tprs_upper,\n",
    "        color=\"grey\",\n",
    "        alpha=0.2,\n",
    "        label=r\"$\\pm$ 1 std. dev.\",\n",
    "    )\n",
    "\n",
    "    ax.set(\n",
    "        xlabel=\"False Positive Rate\",\n",
    "        ylabel=\"True Positive Rate\",\n",
    "        title=f\"Mean ROC curve with variability\",\n",
    "    )\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    return best_X_train, best_y_train, best_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix\n",
    "Werkt niet op classifiers die geen predict_proba hebben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(X_test, y_test, classifier):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_proba = classifier.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classifier.classes_)\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "    print(f\"Accuracy:  {accuracy:.3f}\")\n",
    "    print(f\"Precision: {precision:.3f}\")\n",
    "    print(f\"Recall:    {recall:.3f}\")\n",
    "    print(f\"F1 Score:  {f1:.3f}\")\n",
    "    print(f\"AUC Score: {auc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
